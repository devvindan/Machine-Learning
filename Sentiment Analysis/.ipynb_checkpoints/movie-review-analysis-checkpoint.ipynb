{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie review sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a text of a movie review, predict the sentiment of it. For the following task we are going to use NLTK package and 'movie_reviews' data in particular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movie reviews dataset contains positive and negative movie reviews, and might be downloaded using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\n\\nimport nltk\\nnltk.download(\\'movie_reviews\\')\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "\n",
    "import nltk\n",
    "nltk.download('movie_reviews')\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries for data exprolation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg/cv000_29416.txt',\n",
       " 'neg/cv001_19502.txt',\n",
       " 'neg/cv002_17424.txt',\n",
       " 'neg/cv003_12683.txt',\n",
       " 'neg/cv004_12641.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.fileids()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive reviews: 1000 \n",
      "Negative reviews: 1000\n"
     ]
    }
   ],
   "source": [
    "# selecting negative and positive reviews\n",
    "\n",
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')\n",
    "print(\"Positive reviews: {} \\nNegative reviews: {}\".format(len(posids), len(negids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of words of positive/negative reviews\n",
    "negfeats = [list(movie_reviews.words(fileids=[f])) for f in negids]\n",
    "posfeats = [list(movie_reviews.words(fileids=[f])) for f in posids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalreviews = negfeats + posfeats\n",
    "labels = len(negfeats) * [0] + len(posfeats) * [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews in dataset: 2000\n"
     ]
    }
   ],
   "source": [
    "print(\"Total reviews in dataset: {}\".format(len(totalreviews)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our dataset is perfectly balanced. Half of our reviews are positive, and others are negative.\n",
    "\n",
    "Let's first try to build a simple model without any preprocessing of review words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform our review representation to strings instead of list of words in order to use in vectorizer\n",
    "totalreviews = [\" \".join(review) for review in totalreviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature count: 39659\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(totalreviews)\n",
    "print(\"Feature count: {}\".format(len(vectorizer.get_feature_names())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our vectorizer creates a matrix *documents X tokens*, where each cell represents token frequency\n",
    "\n",
    "Let's build a pipeline with CountVectorizer and LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pipeline = Pipeline(steps=[\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('estimator', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = cross_val_score(clf_pipeline, totalreviews, labels, scoring='accuracy')\n",
    "roc_auc_scores = cross_val_score(clf_pipeline, totalreviews, labels, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy score: 0.8360216503929078\n",
      "Cross-validation roc_auc score: 0.9107764937833774\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross-validation accuracy score: {}\".format(np.mean(accuracy_scores)))\n",
    "print(\"Cross-validation roc_auc score: {}\".format(np.mean(roc_auc_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at top-5 most important parameters (words) according to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 important words according to coefficients: \n",
      "bad\n",
      "unfortunately\n",
      "worst\n",
      "fun\n",
      "waste\n"
     ]
    }
   ],
   "source": [
    "clf_pipeline.fit(totalreviews, labels)\n",
    "print(\"Top 5 important words according to coefficients:\\n\")\n",
    "\n",
    "# look for both negative and positive coefficients\n",
    "\n",
    "indicies = np.argsort(np.abs(clf_pipeline.named_steps['estimator'].coef_[0]))\n",
    "feature_names = clf_pipeline.named_steps['vectorizer'].get_feature_names()\n",
    "\n",
    "for index in reversed(indicies[-5:]):\n",
    "    print(feature_names[index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
